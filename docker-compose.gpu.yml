services:
  backend:
    build: 
      context: .
      dockerfile: Dockerfile.gpu
    image: speak_ai_backend:gpu
    container_name: speak_ai_backend_gpu
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "0.0.0.0:9000:8000"
    volumes:
      - ./:/app
      - ./logs:/app/logs
      - C:\Users\admin\.cache\whisper:/root/.cache/whisper 
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    deploy:
      resources:
        reservations:
          devices:
            - driver : nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - app_speak_ai_network
    depends_on:
      - tts_kokoro
  tts_kokoro: # Service Kokoro TTS
    image: ghcr.io/remsky/kokoro-fastapi-gpu:latest 
    container_name: tts_kokoro_service
    restart: unless-stopped
    ports:
      - "0.0.0.0:8880:8880"

    deploy: 
      resources:
        reservations:
          devices:
            - driver : nvidia
              count: 1 
              capabilities: [gpu]
    networks:
      - app_speak_ai_network
networks:
  app_speak_ai_network:
    driver: bridge